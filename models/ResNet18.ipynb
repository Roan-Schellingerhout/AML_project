{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb6d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfcdbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train_labels.csv\", names=['img_name', 'label'], header=1)\n",
    "\n",
    "df = df.append([df[df[\"label\"] == 20]] * 15, ignore_index = True)\n",
    "df = df.sample(frac=1, random_state = 42).reset_index(drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817964f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class food_set(Dataset):\n",
    "\n",
    "    def __init__(self, df, labels_file, img_dir, extractor, transform = None, settype = \"train\"):\n",
    "        self.df = df\n",
    "        if settype == \"train\":\n",
    "            self.img_labels = df[:30000]\n",
    "        elif settype == \"val\":\n",
    "            self.img_labels = df[30000:]\n",
    "        self.img_dir = img_dir\n",
    "        self.feature_extractor = extractor\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "                \n",
    "        features = self.feature_extractor(images=image)[\"pixel_values\"][0]      \n",
    "        \n",
    "        label = self.img_labels.iloc[idx, 1]       \n",
    "            \n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e17ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class food_test(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = os.listdir(self.img_dir)[idx]\n",
    "        img_path = os.path.join(self.img_dir, file_name)\n",
    "        image = read_image(img_path)\n",
    "       \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return file_name, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f56cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5611)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = \"../data/train_set/train_set\"\n",
    "labels = \"../data/train_labels.csv\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "                    [transforms.Resize((256,256)),\n",
    "                     transforms.ConvertImageDtype(torch.float),\n",
    "                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = food_set(df, labels, img_dir, feature_extractor, transform = transform, settype = \"train\")\n",
    "valset = food_set(df, labels, img_dir, feature_extractor, settype = \"val\")\n",
    "\n",
    "# Create a DataLoader with the data\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(valset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "len(trainset), len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4691e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7653"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = food_test(\"../data/test_set/test_set\", transform = transform)\n",
    "testloader = DataLoader(test_set, batch_size = 32, shuffle=True, num_workers=0)\n",
    "\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb57a8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b18ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "resnet.classifier = nn.Linear(512, 81)\n",
    "\n",
    "resnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c472868",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c7d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(5):\n",
    "        for batch, (image, label) in enumerate(dataloader):\n",
    "            # Compute prediction and loss\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            pred = model(image)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 200 == 0:\n",
    "                loss, current = loss.item(), batch * len(image)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}] epoch: {epoch}\")\n",
    "                \n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        test_loop(valloader, resnet, criterion)\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            pred = model(image)\n",
    "            test_loss += criterion(pred, label).item()\n",
    "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec9852b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.162131  [    0/25000] epoch: 0\n",
      "loss: 2.136808  [ 3200/25000] epoch: 0\n",
      "loss: 1.750791  [ 6400/25000] epoch: 0\n",
      "loss: 1.731623  [ 9600/25000] epoch: 0\n",
      "loss: 1.833570  [12800/25000] epoch: 0\n",
      "loss: 2.120660  [16000/25000] epoch: 0\n",
      "loss: 1.288514  [19200/25000] epoch: 0\n",
      "loss: 2.684976  [22400/25000] epoch: 0\n",
      "Epoch: 0\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.994933 \n",
      "\n",
      "loss: 1.779442  [    0/25000] epoch: 1\n",
      "loss: 1.924853  [ 3200/25000] epoch: 1\n",
      "loss: 1.677375  [ 6400/25000] epoch: 1\n",
      "loss: 1.984255  [ 9600/25000] epoch: 1\n",
      "loss: 1.779712  [12800/25000] epoch: 1\n",
      "loss: 1.079678  [16000/25000] epoch: 1\n",
      "loss: 1.052743  [19200/25000] epoch: 1\n",
      "loss: 1.360638  [22400/25000] epoch: 1\n",
      "Epoch: 1\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.933023 \n",
      "\n",
      "loss: 0.296024  [    0/25000] epoch: 2\n",
      "loss: 0.701001  [ 3200/25000] epoch: 2\n",
      "loss: 0.791915  [ 6400/25000] epoch: 2\n",
      "loss: 0.910121  [ 9600/25000] epoch: 2\n",
      "loss: 1.344705  [12800/25000] epoch: 2\n",
      "loss: 1.433419  [16000/25000] epoch: 2\n",
      "loss: 1.789770  [19200/25000] epoch: 2\n",
      "loss: 0.772245  [22400/25000] epoch: 2\n",
      "Epoch: 2\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.903645 \n",
      "\n",
      "loss: 0.609324  [    0/25000] epoch: 3\n",
      "loss: 0.178196  [ 3200/25000] epoch: 3\n",
      "loss: 0.189093  [ 6400/25000] epoch: 3\n",
      "loss: 0.398303  [ 9600/25000] epoch: 3\n",
      "loss: 0.636890  [12800/25000] epoch: 3\n",
      "loss: 0.454296  [16000/25000] epoch: 3\n",
      "loss: 0.570365  [19200/25000] epoch: 3\n",
      "loss: 0.776770  [22400/25000] epoch: 3\n",
      "Epoch: 3\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.942836 \n",
      "\n",
      "loss: 0.151703  [    0/25000] epoch: 4\n",
      "loss: 0.159801  [ 3200/25000] epoch: 4\n",
      "loss: 0.323042  [ 6400/25000] epoch: 4\n",
      "loss: 0.394560  [ 9600/25000] epoch: 4\n",
      "loss: 0.254593  [12800/25000] epoch: 4\n",
      "loss: 0.152543  [16000/25000] epoch: 4\n",
      "loss: 0.543555  [19200/25000] epoch: 4\n",
      "loss: 0.508331  [22400/25000] epoch: 4\n",
      "Epoch: 4\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 2.004235 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(trainloader, resnet, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d93a4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '../../models/normalized_transfered_resnet.pth'\n",
    "# torch.save(resnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74d758e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet2 = models.resnet18()\n",
    "resnet2.load_state_dict(torch.load(\"../../transfered_resnet.pth\"))\n",
    "resnet2.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32434004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 240/240 [02:49<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "test_results = {\"img_name\" : [], \"label\": []}\n",
    "\n",
    "for file_name, image in tqdm(testloader):\n",
    "    X = image.to(device)\n",
    "    pred = resnet2(X).argmax(1)\n",
    "    \n",
    "    test_results[\"img_name\"] += file_name\n",
    "    test_results[\"label\"] += [int(i) for i in pred.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "752a6d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_6060.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3540.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4430.jpg</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_695.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4999.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img_name  label\n",
       "0  test_6060.jpg     21\n",
       "1  test_3540.jpg      6\n",
       "2  test_4430.jpg     72\n",
       "3   test_695.jpg     10\n",
       "4  test_4999.jpg     37"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_results)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab7cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
